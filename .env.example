
```env
# AI Reviewer Configuration (example)

# Name of the Ollama model to use
OLLAMA_MODEL=llama3:8b

# URL of the Ollama API endpoint (local or remote)
OLLAMA_URL=http://localhost:11434

# Max characters of Git diff to include in the prompt
AI_REVIEW_MAX_DIFF_CHARS=2000

# Max seconds to wait for the AI response
AI_REVIEW_TIMEOUT_SECONDS=300

# Strict mode: if set to 1, any AI failure results in CI failure
AI_REVIEW_STRICT=0
